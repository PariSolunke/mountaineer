{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/mountaineer-gale/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "from dataset.adult.ann_model import ANN_softmax\n",
    "\n",
    "from captum_explainers import explainer_attributes\n",
    "\n",
    "from src.baseline_experiments import *\n",
    "\n",
    "from mountaineer import Mountaineer\n",
    "from gale import create_mapper, bootstrap_mapper_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: Train 36177 | Test 9045\n",
      "Number of features: 13\n",
      "Train Class 0: 27211 | Class 1: 8966\n",
      "Test Class 0: 6803 | Class 1: 2242\n"
     ]
    }
   ],
   "source": [
    "###1. load data and model\n",
    "data_name = 'adult'\n",
    "\n",
    "data = np.loadtxt(f'dataset/{data_name}/X_train_prep.csv', delimiter=',', dtype=np.float64, skiprows=1)\n",
    "X_train = torch.from_numpy(data).float()\n",
    "y_train = np.loadtxt(f'dataset/{data_name}/y_train.csv', delimiter=',', dtype=np.float64, skiprows=1)\n",
    "\n",
    "data = np.loadtxt(f'dataset/{data_name}/X_test_prep.csv', delimiter=',', dtype=np.float64, skiprows=1)\n",
    "X_test = torch.from_numpy(data).float()\n",
    "y_test = np.loadtxt(f'dataset/{data_name}/y_test.csv', delimiter=',', dtype=np.float64, skiprows=1)\n",
    "\n",
    "columns_df = pd.read_csv(f'dataset/{data_name}/X_test_prep.csv', nrows=1)\n",
    "col_names = columns_df.columns\n",
    "\n",
    "print(f\"Number of samples: Train {X_train.shape[0]} | Test {X_test.shape[0]}\")\n",
    "print(f\"Number of features: {X_train.shape[1]}\")\n",
    "print(f\"Train Class 0: {y_train[y_train==0].shape[0]} | Class 1: {y_train[y_train==1].shape[0]}\")\n",
    "print(f\"Test Class 0: {y_test[y_test==0].shape[0]} | Class 1: {y_test[y_test==1].shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.831\n"
     ]
    }
   ],
   "source": [
    "model = ANN_softmax(input_layer=X_train.shape[1],\n",
    "                    hidden_layer_1=100,\n",
    "                    num_of_classes=2)\n",
    "model.load_state_dict(torch.load('dataset/adult/adult_lr_0.002_acc_0.83.pt'))\n",
    "model.eval()\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test).float()\n",
    "proba = model.predict_proba(X_test_tensor)\n",
    "function = np.array([np.squeeze(i) for i in proba])\n",
    "\n",
    "predictions = [1 if function[i][0] < function[i][1] else 0 for i in range(len(function))]\n",
    "\n",
    "function = [function[i][1] for i in range(len(function))]\n",
    "function = np.array(function)\n",
    "\n",
    "X_np = X_test_tensor.detach().numpy()\n",
    "\n",
    "print(f\"Model Accuracy: {sum(predictions == y_test)/len(y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_dic_str = f\"dataset/{data_name}/{data_name}_exp_dict.p\"\n",
    "\n",
    "if Path(exp_dic_str).is_file():\n",
    "    exp_dict = pickle.load(open(exp_dic_str, 'rb'))\n",
    "\n",
    "else:\n",
    "    exp_dict = explainer_attributes(model, X_test, n_perturb = 500)\n",
    "    pickle.dump(exp_dict, open(exp_dic_str, \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the mapper outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'adult-gale'\n",
    "\n",
    "exec_times = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stability for Vanilla Gradient: 0.00103 | Resolution: 30\n",
      "Stability for Gradient x Input: 0.00113 | Resolution: 30\n",
      "Stability for Occlusion: 0.00249 | Resolution: 24\n",
      "Stability for Guided Backprop: 0.00103 | Resolution: 30\n",
      "Stability for LIME: 0.00092 | Resolution: 29\n",
      "Stability for KernelSHAP: 0.00092 | Resolution: 29\n",
      "Stability for SmoothGrad: 0.00103 | Resolution: 30\n",
      "Stability for Integrated Gradients: 0.00096 | Resolution: 28\n"
     ]
    }
   ],
   "source": [
    "gains=[0.1,0.2,0.3,0.4,0.5]\n",
    "resolutions = [i for i in range(10, 31)]\n",
    "distances = [0.1,0.2,0.3,0.4,0.5]\n",
    "\n",
    "heloc_params_str = f\"dataset/{data_name}/{data_name}_params_mapper.p\"\n",
    "\n",
    "best_params = {}\n",
    "mappers = {}\n",
    "\n",
    "if Path(heloc_params_str).is_file():\n",
    "    best_params = pickle.load(open(heloc_params_str, 'rb'))\n",
    "\n",
    "for exp in exp_dict.keys():\n",
    "    exec_times[exp] = {}\n",
    "\n",
    "    if not Path(heloc_params_str).is_file():\n",
    "        \n",
    "        start_time = time.time()\n",
    "\n",
    "        best_params[exp] = bootstrap_mapper_params(exp_dict[exp], function,\n",
    "                            resolutions=resolutions,\n",
    "                            gains=gains,\n",
    "                            distances=distances,\n",
    "                            n=100, \n",
    "                            n_jobs=-1)\n",
    "        \n",
    "        exec_times[exp]['Bootstrap parameters'] = time.time()-start_time\n",
    "        print(f'Time: {exec_times[exp][\"Bootstrap parameters\"]}')\n",
    "    \n",
    "    print(f'Stability for {exp}: {best_params[exp][\"stability\"]:.5f} | Resolution: {best_params[exp][\"resolution\"]}')\n",
    "\n",
    "    start_time = time.time()\n",
    "    mappers[exp] = create_mapper(exp_dict[exp], function, \n",
    "                                 resolution=best_params[exp]['resolution'], \n",
    "                                 gain=best_params[exp]['gain'], \n",
    "                                 dist_thresh=best_params[exp]['distance_threshold'])\n",
    "    if not exec_times is None:\n",
    "        exec_times[exp]['Build mapper'] = time.time()-start_time\n",
    "\n",
    "if not Path(heloc_params_str).is_file():\n",
    "    pickle.dump(best_params, open(heloc_params_str, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Vanilla Gradient': {'Build mapper': 0.34166836738586426},\n",
       " 'Gradient x Input': {'Build mapper': 0.34038400650024414},\n",
       " 'Occlusion': {'Build mapper': 0.3626291751861572},\n",
       " 'Guided Backprop': {'Build mapper': 0.2835366725921631},\n",
       " 'LIME': {'Build mapper': 0.27878546714782715},\n",
       " 'KernelSHAP': {'Build mapper': 0.28390073776245117},\n",
       " 'SmoothGrad': {'Build mapper': 0.28180646896362305},\n",
       " 'Integrated Gradients': {'Build mapper': 0.2749288082122803}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exec_time_str = f\"dataset/{data_name}/{data_name}_exec_time.p\"\n",
    "\n",
    "if not exec_times is None:\n",
    "    pickle.dump(exec_times, open(exec_time_str, \"wb\"))\n",
    "else:\n",
    "    pickle.load(open(exec_time_str, 'rb'))\n",
    "\n",
    "exec_times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_list = ['LIME', 'KernelSHAP', 'Occlusion', 'Integrated Gradients',\n",
    "           'Gradient x Input', 'Vanilla Gradient', 'SmoothGrad']\n",
    "\n",
    "#list of mapper outputs - minimum 2\n",
    "mapper_outputs=[mappers[mode] for mode in exp_list]\n",
    "\n",
    "explanation_vectors=[]\n",
    "for exp in exp_list:\n",
    "    explanation_vectors.append(exp_dict[exp])\n",
    "\n",
    "explanation_list=[]\n",
    "for expl in explanation_vectors:\n",
    "    explanation_list.append(expl.tolist())\n",
    "\n",
    "expl_labels = [exp for exp in exp_list]\n",
    "class_labels = {1:'>50K', 0:\"<=50K\"}\n",
    "\n",
    "color_values = [function]\n",
    "\n",
    "#column names of the dataframe\n",
    "column_names = np.array(col_names.str.replace('-', '_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:1920px !important; }</style>\"))\n",
    "\n",
    "#visualize\n",
    "test = Mountaineer()\n",
    "\n",
    "test.visualize(X_np, y_test, function, explanation_list, mapper_outputs, column_names, \n",
    "              expl_labels, class_labels, kamada_layout=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
