{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from src.baseline_experiments import *\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import glob\n",
    "from mountaineer import Mountaineer\n",
    "from gale import create_mapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Diabetes dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "df = pd.read_csv(\"./dataset/diabetes.csv\")\n",
    "df.drop(columns=[\"p_id\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"diabetes\"])\n",
    "y = df[\"diabetes\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a neural network model with two hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "num_epochs = 80\n",
    "learning_rate = 4e-3\n",
    "N = 100\n",
    "shap_sample_size = 10\n",
    "#possible blur/mean/zero\n",
    "imputation_typ = 'blur'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42)\n",
    "X_train_tens = torch.tensor(X_train.to_numpy()).float()\n",
    "X_test_tens = torch.tensor(X_test.to_numpy()).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "    \n",
    "averaging = 'binary'\n",
    "y_train_tens = torch.tensor(y_train.to_numpy()).view(-1, 1).float()\n",
    "output_dim = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Try to load the model..\n",
      "Train model\n",
      "Epoch 020: | Loss: 0.30523 | Acc: 86.654 | F1: 79.20633\n",
      "Epoch 040: | Loss: 0.28288 | Acc: 90.462 | F1: 85.07238\n",
      "Epoch 060: | Loss: 0.20930 | Acc: 92.577 | F1: 88.17563\n",
      "Epoch 080: | Loss: 0.18856 | Acc: 92.077 | F1: 87.61079\n",
      "Set to eval\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "\n",
    "dataset_tens = torch.utils.data.TensorDataset(X_train_tens, y_train_tens)\n",
    "train_iter = torch.utils.data.DataLoader(dataset_tens, batch_size, shuffle=False)\n",
    "\n",
    "print(\"Try to load the model..\")\n",
    "model = nn_model.get_model(device, train_iter, X_train.shape[1], output_dim, averaging, learning_rate, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m X_test_tens \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(X_test\u001b[38;5;241m.\u001b[39mto_numpy())\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m----> 3\u001b[0m X_test_c, Y_test_c \u001b[38;5;241m=\u001b[39m get_correct_predictions(model,X_test\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),X_test_tens,y_test\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),averaging)\n\u001b[1;32m      4\u001b[0m X_test_c_tens \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(X_test_c\u001b[38;5;241m.\u001b[39mto_numpy(dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32))\n",
      "File \u001b[0;32m~/Desktop/mountaineer/src/baseline_experiments.py:212\u001b[0m, in \u001b[0;36mget_correct_predictions\u001b[0;34m(model, X_test, X_test_tens, Y_test, averaging)\u001b[0m\n\u001b[1;32m    209\u001b[0m y_pred_label \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mround(torch\u001b[38;5;241m.\u001b[39msigmoid(predictions)) \u001b[38;5;28;01mif\u001b[39;00m averaging \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mmax(predictions\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    211\u001b[0m xs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(X_test, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m--> 212\u001b[0m ys \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(Y_test, dtype\u001b[38;5;241m=\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint\u001b[49m) \u001b[38;5;28;01mif\u001b[39;00m averaging \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(Y_test, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, prediction, y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28menumerate\u001b[39m(xs), y_pred_label, ys):\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m prediction \u001b[38;5;241m==\u001b[39m y:\n",
      "File \u001b[0;32m~/miniconda3/envs/mountaineer/lib/python3.9/site-packages/numpy/__init__.py:305\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    300\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    301\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn the future `np.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` will be defined as the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    302\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorresponding NumPy scalar.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m __former_attrs__:\n\u001b[0;32m--> 305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(__former_attrs__[attr])\n\u001b[1;32m    307\u001b[0m \u001b[38;5;66;03m# Importing Tester requires importing all of UnitTest which is not a\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;66;03m# cheap import Since it is mainly used in test suits, we lazy import it\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;66;03m# here to save on the order of 10 ms of import time for most users\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;66;03m# The previous way Tester was imported also had a side effect of adding\u001b[39;00m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;66;03m# the full `numpy.testing` namespace\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtesting\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "X_test_tens = torch.tensor(X_test.to_numpy()).float()\n",
    "\n",
    "X_test_c, Y_test_c = get_correct_predictions(model,X_test.reset_index(drop=True),X_test_tens,y_test.reset_index(drop=True),averaging)\n",
    "X_test_c_tens = torch.from_numpy(X_test_c.to_numpy(dtype=np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the sigmoid function as the prediction probability function for Mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = torch.sigmoid(model(X_test_tens)).detach().numpy()\n",
    "plt.plot(np.sort(predictions.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the Explanations of (IntGrad, SHAP, DeepLIFT) $\\times$ (Zero, Max Distances, Uniform, Gaussian, Train)-Baselines (15 explanation outputs in total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading all baselines..\")\n",
    "bun = BaselineUtilTensor()\n",
    "black_baseline = bun.create_black_baseline(X)\n",
    "uniform_baseline = bun.create_uniform_baseline(X)\n",
    "gaussian_baseline = bun.create_gaussian_baseline(X, 0.5)\n",
    "train_baseline = bun.create_train_baseline(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "explanations = {}\n",
    "methods = ['IG','DeepSHAP','DeepLIFT']\n",
    "target = None\n",
    "for method in methods:\n",
    "    bb_attr, mdb_attr, ub_attr, gb_attr, tb_attr = get_attr_scores(method, X_test_tens, None, black_baseline,uniform_baseline,gaussian_baseline, train_baseline, model,X.min(), X.max(), X.columns)\n",
    "    explanations[method] = [bb_attr, mdb_attr, ub_attr, gb_attr, tb_attr]\n",
    "    #for exp in explanations[method]:\n",
    "        #exp[exp>5]=5\n",
    "        #exp[exp<-5]=-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#baselines = ['zero', 'max distance', 'uniform', 'gaussian', 'trained']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the mapper outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "mapper1 = create_mapper(explanations['IG'][0], np.array([np.squeeze(i) for i in predictions]), resolution=10, gain=0.4, dist_thresh=0.5)\n",
    "mapper2 = create_mapper(explanations['IG'][1], np.array([np.squeeze(i) for i in predictions]), resolution=10, gain=0.4, dist_thresh=0.5)\n",
    "mapper3 = create_mapper(explanations['IG'][2], np.array([np.squeeze(i) for i in predictions]), resolution=10, gain=0.4, dist_thresh=0.5)\n",
    "mapper4 = create_mapper(explanations['IG'][3], np.array([np.squeeze(i) for i in predictions]), resolution=10, gain=0.4, dist_thresh=0.5)\n",
    "mapper5 = create_mapper(explanations['IG'][4], np.array([np.squeeze(i) for i in predictions]), resolution=10, gain=0.4, dist_thresh=0.5)\n",
    "\n",
    "mapper6 = create_mapper(explanations['DeepSHAP'][0], np.array([np.squeeze(i) for i in predictions]), resolution=10, gain=0.4, dist_thresh=0.5)\n",
    "mapper7 = create_mapper(explanations['DeepSHAP'][1], np.array([np.squeeze(i) for i in predictions]), resolution=10, gain=0.4, dist_thresh=0.5)\n",
    "mapper8 = create_mapper(explanations['DeepSHAP'][2], np.array([np.squeeze(i) for i in predictions]), resolution=10, gain=0.4, dist_thresh=0.5)\n",
    "mapper9 = create_mapper(explanations['DeepSHAP'][3], np.array([np.squeeze(i) for i in predictions]), resolution=10, gain=0.4, dist_thresh=0.5)\n",
    "mapper10 = create_mapper(explanations['DeepSHAP'][4], np.array([np.squeeze(i) for i in predictions]), resolution=10, gain=0.4, dist_thresh=0.5)\n",
    "\n",
    "\n",
    "mapper11 = create_mapper(explanations['DeepLIFT'][0], np.array([np.squeeze(i) for i in predictions]), resolution=10, gain=0.4, dist_thresh=0.5)\n",
    "mapper12 = create_mapper(explanations['DeepLIFT'][1], np.array([np.squeeze(i) for i in predictions]), resolution=10, gain=0.4, dist_thresh=0.5)\n",
    "mapper13 = create_mapper(explanations['DeepLIFT'][2], np.array([np.squeeze(i) for i in predictions]), resolution=10, gain=0.4, dist_thresh=0.5)\n",
    "mapper14 = create_mapper(explanations['DeepLIFT'][3], np.array([np.squeeze(i) for i in predictions]), resolution=10, gain=0.4, dist_thresh=0.5)\n",
    "mapper15 = create_mapper(explanations['DeepLIFT'][4], np.array([np.squeeze(i) for i in predictions]), resolution=10, gain=0.4, dist_thresh=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:1920px !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:1920px !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mapper1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#list of mapper outputs - minimum 2\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m mapper_outputs\u001b[38;5;241m=\u001b[39m[mapper1, mapper2, mapper3, mapper4, mapper5, mapper6, mapper7, mapper8, mapper9, mapper10, mapper11, mapper12, mapper13, mapper14, mapper15]\n\u001b[1;32m      4\u001b[0m explanation_vectors\u001b[38;5;241m=\u001b[39m[explanations[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIG\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m],explanations[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIG\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m1\u001b[39m],explanations[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIG\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m2\u001b[39m],explanations[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIG\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m3\u001b[39m],explanations[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIG\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m4\u001b[39m],  explanations[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDeepSHAP\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m], explanations[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDeepSHAP\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m1\u001b[39m], explanations[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDeepSHAP\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m2\u001b[39m], explanations[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDeepSHAP\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m3\u001b[39m], explanations[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDeepSHAP\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m4\u001b[39m], explanations[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDeepLIFT\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m], explanations[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDeepLIFT\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m1\u001b[39m], explanations[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDeepLIFT\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m2\u001b[39m], explanations[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDeepLIFT\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m3\u001b[39m], explanations[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDeepLIFT\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m4\u001b[39m]]\n\u001b[1;32m      5\u001b[0m explanation_list\u001b[38;5;241m=\u001b[39m[]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mapper1' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "#list of mapper outputs - minimum 2\n",
    "mapper_outputs=[mapper1, mapper2, mapper3, mapper4, mapper5, mapper6, mapper7, mapper8, mapper9, mapper10, mapper11, mapper12, mapper13, mapper14, mapper15]\n",
    "\n",
    "explanation_vectors=[explanations['IG'][0],explanations['IG'][1],explanations['IG'][2],explanations['IG'][3],explanations['IG'][4],  explanations['DeepSHAP'][0], explanations['DeepSHAP'][1], explanations['DeepSHAP'][2], explanations['DeepSHAP'][3], explanations['DeepSHAP'][4], explanations['DeepLIFT'][0], explanations['DeepLIFT'][1], explanations['DeepLIFT'][2], explanations['DeepLIFT'][3], explanations['DeepLIFT'][4]]\n",
    "explanation_list=[]\n",
    "for expl in explanation_vectors:\n",
    "    explanation_list.append(expl.tolist())\n",
    "predicted_prob = np.array([np.squeeze(i) for i in predictions])\n",
    "expl_labels=['IG_ZB', 'IG_MB', 'IG_UB', 'IG_GB', 'IG_TB', 'DS_ZB', 'DS_MB', 'DS_UB', 'DS_GB', 'DS_TB', 'DL_ZB', 'DL_MB', 'DL_UB', 'DL_GB', 'DL_TB'] \n",
    "\n",
    "#column names of the dataframe\n",
    "column_names= np.array(X.columns)\n",
    "class_labels = {1:\"Diabetic\", 0:\"Non Diabetic\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predicted_prob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [11], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#visualize\u001b[39;00m\n\u001b[1;32m      2\u001b[0m mnt \u001b[38;5;241m=\u001b[39m Mountaineer()\n\u001b[0;32m----> 3\u001b[0m mnt\u001b[38;5;241m.\u001b[39mvisualize(X_test\u001b[38;5;241m.\u001b[39mto_numpy(),y_test\u001b[38;5;241m.\u001b[39mto_numpy(), predicted_prob, explanation_list, mapper_outputs, column_names, expl_labels, class_labels)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predicted_prob' is not defined"
     ]
    }
   ],
   "source": [
    "#visualize\n",
    "mnt = Mountaineer()\n",
    "mnt.visualize(X_test.to_numpy(),y_test.to_numpy(), predicted_prob, explanation_list, mapper_outputs, column_names, expl_labels, class_labels) #Projection method- 'UMAP' or 'TSNE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  88.29104764,   49.91734716,  797.81816227,  175.17331936,\n",
       "        769.54749645,  389.75980937,    6.34245809, 1554.15616189])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mean of explanation attributions for every feature zero baseline Integrated Gradient\n",
    "np.max(explanation_vectors[0], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8492.13286346, 14595.81531351,  6431.98618104, -4799.87846332,\n",
       "        3101.18180703, -2723.83870671,  1184.22380482, 15918.78830806])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#means of explanation attributions for every feature for max distance baseline Integrated Gradients\n",
    "np.mean(explanation_vectors[1], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.6603706 ,  -9.0945436 ,   0.        ,  -3.46607467,\n",
       "       -10.6932722 ,   0.        ,   0.88227119,   6.25249074])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mean of explanation attributions for every feature zero baseline Integrated Gradient\n",
    "np.median(explanation_vectors[0], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  -17.46102124, -1068.11921051,  -277.73046875,  -173.98871572,\n",
       "        -144.92184172,  -432.33702606,   -29.68376723,  -424.4705105 ])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(explanation_vectors[0], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_times_pregnant</th>\n",
       "      <th>glucose_concentration</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>skin_fold_thickness</th>\n",
       "      <th>serum_insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>diabetes pedigree</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>203.000000</td>\n",
       "      <td>203.000000</td>\n",
       "      <td>203.000000</td>\n",
       "      <td>203.000000</td>\n",
       "      <td>203.000000</td>\n",
       "      <td>203.000000</td>\n",
       "      <td>203.000000</td>\n",
       "      <td>203.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.019704</td>\n",
       "      <td>119.832512</td>\n",
       "      <td>68.857143</td>\n",
       "      <td>21.024631</td>\n",
       "      <td>84.177340</td>\n",
       "      <td>31.002956</td>\n",
       "      <td>0.451823</td>\n",
       "      <td>34.802956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.422350</td>\n",
       "      <td>32.489473</td>\n",
       "      <td>20.245383</td>\n",
       "      <td>15.851551</td>\n",
       "      <td>121.087719</td>\n",
       "      <td>8.567547</td>\n",
       "      <td>0.279240</td>\n",
       "      <td>12.898714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.085000</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.800000</td>\n",
       "      <td>0.255000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>31.200000</td>\n",
       "      <td>0.361000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>131.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.629500</td>\n",
       "      <td>42.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>196.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>49.700000</td>\n",
       "      <td>1.731000</td>\n",
       "      <td>81.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       no_times_pregnant  glucose_concentration  blood_pressure  \\\n",
       "count         203.000000             203.000000      203.000000   \n",
       "mean            4.019704             119.832512       68.857143   \n",
       "std             3.422350              32.489473       20.245383   \n",
       "min             0.000000               0.000000        0.000000   \n",
       "25%             1.000000              99.000000       62.000000   \n",
       "50%             3.000000             117.000000       72.000000   \n",
       "75%             6.000000             138.000000       80.000000   \n",
       "max            17.000000             196.000000      104.000000   \n",
       "\n",
       "       skin_fold_thickness  serum_insulin         bmi  diabetes pedigree  \\\n",
       "count           203.000000     203.000000  203.000000         203.000000   \n",
       "mean             21.024631      84.177340   31.002956           0.451823   \n",
       "std              15.851551     121.087719    8.567547           0.279240   \n",
       "min               0.000000       0.000000    0.000000           0.085000   \n",
       "25%               0.000000       0.000000   26.800000           0.255000   \n",
       "50%              23.000000      48.000000   31.200000           0.361000   \n",
       "75%              32.000000     131.000000   36.000000           0.629500   \n",
       "max              54.000000     846.000000   49.700000           1.731000   \n",
       "\n",
       "              age  \n",
       "count  203.000000  \n",
       "mean    34.802956  \n",
       "std     12.898714  \n",
       "min     21.000000  \n",
       "25%     24.000000  \n",
       "50%     31.000000  \n",
       "75%     42.500000  \n",
       "max     81.000000  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
